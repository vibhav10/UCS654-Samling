{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = center> Sampling Assignment - UCS654 </h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align = right>  \n",
    "Vibhav Shukla </br>\n",
    "102003772 </br>\n",
    "3CO30 \n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataframe\n",
    "df = pd.read_csv('Creditcard_data.csv')\n",
    "#drop the time column\n",
    "df = df.drop(['Time'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert the dataset into a balanced class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df['Class'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    763\n",
      "1      9\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# separate the features and target variable\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "print(y.value_counts())\n",
    "# create a balanced dataset using SMOTE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As visible, the dataset is highly imbalanced. We will use SMOTE to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763\n",
       "1    763\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "df_new = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print the bar graph\n",
    "df_new['Class'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ogtrain, x_ogtest, y_ogtrain, y_ogtest = train_test_split(df.drop('Class', axis=1), df['Class'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using 5 Sampling Methods\n",
    "##### 2.1) Simple Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 30)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use simple random sampling to create a balanced dataset\n",
    "df_simple_random = df.sample(frac=1, random_state=42)\n",
    "df_simple_random.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2) Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 30)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use stratified sampling to create a balanced dataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "def stratified_sampling(df, n_samples=2):\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=n_samples, random_state=42)\n",
    "    for train_index, test_index in sss.split(df, df['Class']):\n",
    "        strat_train_set = df.loc[train_index]\n",
    "        strat_test_set = df.loc[test_index]\n",
    "    return strat_test_set\n",
    "\n",
    "\n",
    "\n",
    "df_stratified = stratified_sampling(df_new, 110)\n",
    "df_stratified.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3) Cluster Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Cluster sampling to create a balanced dataset\n",
    "\n",
    "def cluster_sampling(df2, n_clusters=5, n_samples=2):\n",
    "    df = df2.copy()\n",
    "    X = df.drop('Class', axis=1)\n",
    "    y = df['Class']\n",
    "    k = n_clusters\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "\n",
    "    df['Cluster'] = clusters\n",
    "\n",
    "    sampled_clusters = np.random.choice(range(k), size=n_samples, replace=False)\n",
    "    strat_train_set = pd.DataFrame()\n",
    "    for c in sampled_clusters:\n",
    "        cluster = df[df['Cluster'] == c]\n",
    "        n = len(cluster)\n",
    "        sample = cluster.sample(n // 2, random_state=42)\n",
    "        strat_train_set = pd.concat([strat_train_set, sample])\n",
    "\n",
    "    cluster_train_set = strat_train_set.drop('Cluster', axis=1)\n",
    "    \n",
    "    return cluster_train_set\n",
    "\n",
    "df_cluster = cluster_sampling(df_new, n_clusters=5, n_samples=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4) Systematic Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def systematic_sampling(df_func, step):\n",
    " \n",
    "    indexes = np.arange(0, len(df_func), step=step)\n",
    "    systematic_sample = df_func.iloc[indexes]\n",
    "    return systematic_sample\n",
    "\n",
    "df_systematic = systematic_sampling(df_new, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5) Reservoir Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vibha\\AppData\\Local\\Temp\\ipykernel_23828\\1605643507.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  res = res.append(row)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def reservoir_sampling(df, n_samples):\n",
    "    res = df.iloc[:n_samples, :]\n",
    "    i = n_samples\n",
    "    for index, row in df.iterrows():\n",
    "        if i > n_samples:\n",
    "            j = random.randint(0, i)\n",
    "            if j < n_samples:\n",
    "                res.iloc[j] = row\n",
    "        else:\n",
    "            res = res.append(row)\n",
    "        i += 1\n",
    "    return res\n",
    "\n",
    "df_reservoir = reservoir_sampling(df_new, n_samples=110)\n",
    "df_new.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Using 5 different ML models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def Logistic(X_train, y_train, X_test, y_test):\n",
    "  clf = LogisticRegression()\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.predict(X_test)\n",
    "  return accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def DecisionTree(X_train, y_train, X_test, y_test):\n",
    "  tree = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train)\n",
    "  tree_pred = tree.predict(X_test)\n",
    "  return accuracy_score(y_test,tree_pred)\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def RandomForest(X_train, y_train, X_test, y_test):\n",
    "  clf = RandomForestClassifier(n_estimators = 2)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.predict(X_test)\n",
    "  return accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4) KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def KNN(X_train, y_train, X_test, y_test):\n",
    "  knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train)\n",
    "  knn_pred = knn.predict(X_test)\n",
    "  return accuracy_score(y_test,knn_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def NaiveBayes(X_train, y_train, X_test, y_test):\n",
    "  clf = GaussianNB()\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.predict(X_test)\n",
    "  return accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Comparing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['Sampling Method', 'Logistic Regression', 'Decision Tree', 'Random Forest', 'KNN', 'Naive Bayes'])\n",
    "sampling_methods = ['Simple Random Sampling', 'Stratified Sampling', 'Cluster Sampling', 'Systematic Sampling', 'Reservoir Sampling']\n",
    "df_results['Sampling Method'] = sampling_methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1) Simple Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.9935483870967742\n",
      "Decision Tree:  0.9935483870967742\n",
      "Random Forest:  1.0\n",
      "KNN:  0.9935483870967742\n",
      "Naive Bayes:  0.9806451612903225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vibha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#run all the models on the df_simple_random dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_simple_random.drop('Class', axis=1), df_simple_random['Class'], test_size=0.2, random_state=42)\n",
    "\n",
    "#add the results to the dataframe and print them\n",
    "df_results.loc[0, 'Logistic Regression'] = Logistic(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Logistic Regression: ',df_results.loc[0, 'Logistic Regression'])\n",
    "df_results.loc[0, 'Decision Tree'] = DecisionTree(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Decision Tree: ',df_results.loc[0, 'Decision Tree'])\n",
    "df_results.loc[0, 'Random Forest'] = RandomForest(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Random Forest: ',df_results.loc[0, 'Random Forest'])\n",
    "df_results.loc[0, 'KNN'] = KNN(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('KNN: ',df_results.loc[0, 'KNN'])\n",
    "df_results.loc[0, 'Naive Bayes'] = NaiveBayes(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Naive Bayes: ',df_results.loc[0, 'Naive Bayes'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2) Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.6967741935483871\n",
      "Decision Tree:  0.7870967741935484\n",
      "Random Forest:  0.9354838709677419\n",
      "KNN:  0.7741935483870968\n",
      "Naive Bayes:  0.8258064516129032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vibha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_stratified.drop('Class', axis=1), df_stratified['Class'], test_size=0.2, random_state=42)\n",
    "#add to the dataframe and print the results\n",
    "df_results.loc[1, 'Logistic Regression'] = Logistic(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Logistic Regression: ',df_results.loc[1, 'Logistic Regression'])\n",
    "df_results.loc[1, 'Decision Tree'] = DecisionTree(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Decision Tree: ',df_results.loc[1, 'Decision Tree'])\n",
    "df_results.loc[1, 'Random Forest'] = RandomForest(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Random Forest: ',df_results.loc[1, 'Random Forest'])\n",
    "df_results.loc[1, 'KNN'] = KNN(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('KNN: ',df_results.loc[1, 'KNN'])\n",
    "df_results.loc[1, 'Naive Bayes'] = NaiveBayes(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Naive Bayes: ',df_results.loc[1, 'Naive Bayes'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3) Cluster Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.6967741935483871\n",
      "Decision Tree:  0.7870967741935484\n",
      "Random Forest:  0.9354838709677419\n",
      "KNN:  0.7741935483870968\n",
      "Naive Bayes:  0.8258064516129032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vibha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_cluster.drop('Class', axis=1), df_cluster['Class'], test_size=0.2, random_state=42)\n",
    "#add to the dataframe and print the results\n",
    "df_results.loc[2, 'Logistic Regression'] = Logistic(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Logistic Regression: ',df_results.loc[1, 'Logistic Regression'])\n",
    "df_results.loc[2, 'Decision Tree'] = DecisionTree(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Decision Tree: ',df_results.loc[1, 'Decision Tree'])\n",
    "df_results.loc[2, 'Random Forest'] = RandomForest(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Random Forest: ',df_results.loc[1, 'Random Forest'])\n",
    "df_results.loc[2, 'KNN'] = KNN(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('KNN: ',df_results.loc[1, 'KNN'])\n",
    "df_results.loc[2, 'Naive Bayes'] = NaiveBayes(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Naive Bayes: ',df_results.loc[1, 'Naive Bayes'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4) Systematic Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.6967741935483871\n",
      "Decision Tree:  0.7870967741935484\n",
      "Random Forest:  0.9354838709677419\n",
      "KNN:  0.7741935483870968\n",
      "Naive Bayes:  0.8258064516129032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vibha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_stratified.drop('Class', axis=1), df_stratified['Class'], test_size=0.2, random_state=42)\n",
    "#add to the dataframe and print the results\n",
    "df_results.loc[3, 'Logistic Regression'] = Logistic(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Logistic Regression: ',df_results.loc[1, 'Logistic Regression'])\n",
    "df_results.loc[3, 'Decision Tree'] = DecisionTree(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Decision Tree: ',df_results.loc[1, 'Decision Tree'])\n",
    "df_results.loc[3, 'Random Forest'] = RandomForest(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Random Forest: ',df_results.loc[1, 'Random Forest'])\n",
    "df_results.loc[3, 'KNN'] = KNN(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('KNN: ',df_results.loc[1, 'KNN'])\n",
    "df_results.loc[3, 'Naive Bayes'] = NaiveBayes(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Naive Bayes: ',df_results.loc[1, 'Naive Bayes'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5) Reservoir Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 29) (23, 29) (88,) (23,)\n",
      "Logistic Regression:  0.6967741935483871\n",
      "Decision Tree:  0.7870967741935484\n",
      "Random Forest:  0.9354838709677419\n",
      "KNN:  0.7741935483870968\n",
      "Naive Bayes:  0.8258064516129032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vibha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_reservoir.drop('Class', axis=1), df_reservoir['Class'], test_size=0.2, random_state=42)\n",
    "#add to the dataframe and print the results\n",
    "print(x_ogtest.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "df_results.loc[4, 'Logistic Regression'] = Logistic(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Logistic Regression: ',df_results.loc[1, 'Logistic Regression'])\n",
    "df_results.loc[4, 'Decision Tree'] = DecisionTree(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Decision Tree: ',df_results.loc[1, 'Decision Tree'])\n",
    "df_results.loc[4, 'Random Forest'] = RandomForest(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Random Forest: ',df_results.loc[1, 'Random Forest'])\n",
    "df_results.loc[4, 'KNN'] = KNN(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('KNN: ',df_results.loc[1, 'KNN'])\n",
    "\n",
    "df_results.loc[4, 'Naive Bayes'] = NaiveBayes(x_train, y_train, x_ogtest, y_ogtest)\n",
    "print('Naive Bayes: ',df_results.loc[1, 'Naive Bayes'])\n",
    "df_results = df_results.iloc[:, :6]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final Results #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampling Method</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Naive Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple Random Sampling</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.980645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stratified Sampling</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.825806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cluster Sampling</td>\n",
       "      <td>0.83871</td>\n",
       "      <td>0.987097</td>\n",
       "      <td>0.987097</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.993548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Systematic Sampling</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.825806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reservoir Sampling</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>0.83871</td>\n",
       "      <td>0.941935</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.703226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sampling Method Logistic Regression Decision Tree Random Forest  \\\n",
       "0  Simple Random Sampling            0.993548      0.993548           1.0   \n",
       "1     Stratified Sampling            0.696774      0.787097      0.935484   \n",
       "2        Cluster Sampling             0.83871      0.987097      0.987097   \n",
       "3     Systematic Sampling            0.696774      0.787097           0.8   \n",
       "4      Reservoir Sampling            0.819355       0.83871      0.941935   \n",
       "\n",
       "        KNN Naive Bayes  \n",
       "0  0.993548    0.980645  \n",
       "1  0.774194    0.825806  \n",
       "2  0.980645    0.993548  \n",
       "3  0.774194    0.825806  \n",
       "4       0.8    0.703226  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "960f8064da7791162a34228ac1ae9476a4db61176ac8b99a9b82fa9aa4d278d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
